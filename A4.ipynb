{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8c8720",
   "metadata": {},
   "source": [
    "# BERT and Sentence-BERT for Natural Language Inference\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive pipeline for natural language understanding, starting with BERT pre-training from scratch using Masked Language Model (MLM) and Next Sentence Prediction (NSP) objectives, then extending to Sentence-BERT with Siamese network architecture for Natural Language Inference classification.\n",
    "\n",
    "**Pipeline:** BookCorpus → BERT Pre-training → SNLI Fine-tuning → Web Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771cac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from random import randrange, randint, shuffle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0cd99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f07038",
   "metadata": {},
   "source": [
    "## BERT Pre-training from Scratch\n",
    "\n",
    "![BERT Embedding Architecture](figures/BERT_embed.png)\n",
    "\n",
    "**Dataset source:** BookCorpus (Hugging Face, `bookcorpus/bookcorpus`)\n",
    "\n",
    "**Implementation approach:** Following the original BERT paper, we implement bidirectional encoder representations using transformer architecture with masked language modeling and next sentence prediction objectives.\n",
    "\n",
    "**Subset rationale:** Using 5M documents subset for computational efficiency while maintaining training effectiveness.\n",
    "\n",
    "### Data Preprocessing Pipeline\n",
    "We implement a comprehensive preprocessing pipeline: sentence segmentation using spaCy, text normalization (lowercase, punctuation removal), and custom tokenization with special tokens for BERT training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e8f009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125974-ml/.local/lib/python3.12/site-packages/datasets/load.py:1461: FutureWarning: The repository for bookcorpus contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bookcorpus\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 5000000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a subset of BookCorpus\n",
    "subset_size = 5000000\n",
    "raw_dataset = load_dataset(\"bookcorpus\", \"plain_text\", split=\"train\")\n",
    "raw_dataset = raw_dataset.shuffle(seed=seed).select(list(range(subset_size)))\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8135e9-32a8-4199-961b-5f0893642057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using en_core_web_sm\n",
      "Processing with All cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmenting: 100%|██████████| 5000000/5000000 [1:08:25<00:00, 1217.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 5072019\n",
      "Sample sentences: ['asked smart humik ', 'he held her back and looked directly at her ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parallel Setence for Performance\n",
    "\n",
    "# 1. Setup spaCy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Using en_core_web_sm\")\n",
    "except OSError:\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    print(\"Using blank en + sentencizer\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# 2. Define a generator to yield texts (saves memory vs creating a giant list)\n",
    "def text_generator(dataset):\n",
    "    for item in dataset:\n",
    "        text = item[\"text\"]\n",
    "        if text:\n",
    "            yield text\n",
    "\n",
    "sentences = []\n",
    "batch_size = 1000  # Adjust based on memory (larger = slightly faster but more RAM)\n",
    "\n",
    "# 3. Use nlp.pipe with n_process=-1 (Use all available cores)\n",
    "# We wrap the generator in tqdm for a progress bar\n",
    "print(f\"Processing with All cores...\") # Note: might default to 1 in print, strictly set in pipe below\n",
    "\n",
    "# Use n_process=-1 to auto-detect all available cores\n",
    "doc_stream = nlp.pipe(\n",
    "    text_generator(raw_dataset), \n",
    "    batch_size=batch_size, \n",
    "    n_process=-1\n",
    ")\n",
    "\n",
    "for doc in tqdm(doc_stream, total=len(raw_dataset), desc=\"Segmenting\"):\n",
    "    for sent in doc.sents:\n",
    "        # 4. Clean the text AFTER identifying the sentence boundary\n",
    "        clean_s = sent.text.strip().lower()\n",
    "        clean_s = re.sub(r\"[.,!?\\-]\", \"\", clean_s)\n",
    "        \n",
    "        if clean_s:\n",
    "            sentences.append(clean_s)\n",
    "\n",
    "print(\"Total sentences:\", len(sentences))\n",
    "print(\"Sample sentences:\", sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5ae427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "special_tokens = [\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\"]\n",
    "word_list = list(set(\" \\n\".join(sentences).split()))\n",
    "word2id = {tok: idx for idx, tok in enumerate(special_tokens)}\n",
    "for i, w in enumerate(word_list):\n",
    "    if w not in word2id:\n",
    "        word2id[w] = i + len(special_tokens)\n",
    "id2word = {i: w for w, i in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24eec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5071903,\n",
       " [[283921, 156462, 302967],\n",
       "  [129894, 59487, 305353, 275122, 249662, 25887, 70547, 271327, 305353]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per-sentence tokenization (each sentence -> one token list)\n",
    "token_list = []\n",
    "for sent in sentences:\n",
    "    tokens = []\n",
    "    for word in sent.split():\n",
    "        tokens.append(word2id.get(word, word2id[\"[UNK]\"]))\n",
    "    if tokens:\n",
    "        token_list.append(tokens)\n",
    "\n",
    "len(token_list), token_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e963fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader config (smaller values for local training)\n",
    "batch_size = 8\n",
    "max_mask = 8\n",
    "max_len = 64\n",
    "n_segments = 2\n",
    "\n",
    "pad_id = word2id[\"[PAD]\"]\n",
    "cls_id = word2id[\"[CLS]\"]\n",
    "sep_id = word2id[\"[SEP]\"]\n",
    "mask_id = word2id[\"[MASK]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51fc48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    batch = []\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    while positive != batch_size // 2 or negative != batch_size // 2:\n",
    "        tokens_a_index, tokens_b_index = randrange(len(token_list)), randrange(len(token_list))\n",
    "        tokens_a = token_list[tokens_a_index]\n",
    "        tokens_b = token_list[tokens_b_index]\n",
    "\n",
    "        # Truncate to fit max_len with [CLS] and two [SEP]\n",
    "        max_tokens = max_len - 3\n",
    "        tokens_a = tokens_a[: max_tokens // 2]\n",
    "        tokens_b = tokens_b[: max_tokens - len(tokens_a)]\n",
    "\n",
    "        # 1) token embedding\n",
    "        input_ids = [cls_id] + tokens_a + [sep_id] + tokens_b + [sep_id]\n",
    "\n",
    "        # 2) segment embedding\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        # 3) masking\n",
    "        n_pred = min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
    "        candidates_masked_pos = [i for i, token in enumerate(input_ids) if token not in (cls_id, sep_id)]\n",
    "        shuffle(candidates_masked_pos)\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        for pos in candidates_masked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            r = random.random()\n",
    "            if r < 0.1:\n",
    "                index = randint(0, vocab_size - 1)\n",
    "                input_ids[pos] = index\n",
    "            elif r < 0.9:\n",
    "                input_ids[pos] = mask_id\n",
    "\n",
    "        # 4) pad\n",
    "        n_pad = max_len - len(input_ids)\n",
    "        input_ids.extend([pad_id] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        # 5) pad masked tokens\n",
    "        if max_mask > n_pred:\n",
    "            masked_tokens.extend([pad_id] * (max_mask - n_pred))\n",
    "            masked_pos.extend([pad_id] * (max_mask - n_pred))\n",
    "\n",
    "        # 6) NSP label\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size // 2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size // 2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n",
    "            negative += 1\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8bfa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 64]),\n",
       " torch.Size([8, 64]),\n",
       " torch.Size([8, 8]),\n",
       " torch.Size([8, 8]),\n",
       " torch.Size([8]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = make_batch()\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, is_next = map(torch.LongTensor, zip(*batch))\n",
    "input_ids.shape, segment_ids.shape, masked_tokens.shape, masked_pos.shape, is_next.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575561ce",
   "metadata": {},
   "source": [
    "### BERT Architecture Implementation\n",
    "\n",
    "Implementing core BERT components following the transformer architecture:\n",
    "\n",
    "- **Embedding Layer**: Token, position, and segment embeddings with layer normalization\n",
    "- **Multi-Head Attention**: Scaled dot-product attention mechanism with multiple heads\n",
    "- **Encoder Layers**: Stacked transformer blocks with residual connections\n",
    "- **Position-wise FFN**: Feed-forward networks with GELU activation\n",
    "- **Training Objectives**: MLM (15% masking) + NSP (sentence pair prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c703e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters (smaller for local training)\n",
    "n_layers = 2\n",
    "n_heads = 4\n",
    "d_model = 128\n",
    "d_ff = 512\n",
    "d_k = d_v = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae503ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long, device=x.device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e69d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    _, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(pad_id).unsqueeze(1)\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b312b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25dcdfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
    "        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v)\n",
    "        output = self.fc(context)\n",
    "        return self.norm(output + residual), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab482d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2438571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69d2e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding()\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "\n",
    "    def encode(self, input_ids, segment_ids):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
    "        for layer in self.layers:\n",
    "            output, _ = layer(output, enc_self_attn_mask)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.encode(input_ids, segment_ids)\n",
    "\n",
    "        h_pooled = self.activ(self.fc(output[:, 0]))\n",
    "        logits_nsp = self.classifier(h_pooled)\n",
    "\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1))\n",
    "        h_masked = torch.gather(output, 1, masked_pos)\n",
    "        h_masked = self.norm(F.gelu(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias\n",
    "\n",
    "        return logits_lm, logits_nsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343cd395",
   "metadata": {},
   "source": [
    "### BERT Pre-training Configuration\n",
    "\n",
    "**Model Hyperparameters:**\n",
    "- Architecture: 2-layer, 4-head transformer\n",
    "- Hidden dimensions: 128 (d_model), 512 (d_ff)\n",
    "- Sequence length: 64 tokens maximum\n",
    "- Vocabulary: Custom tokenizer on BookCorpus\n",
    "\n",
    "**Training Configuration:**\n",
    "- Batch size: 8 (memory-optimized)\n",
    "- Masking strategy: 15% with 80% [MASK], 10% random, 10% unchanged\n",
    "- Epochs: 10 for convergence\n",
    "- Optimizer: Adam with 1e-3 learning rate\n",
    "- Objectives: Combined MLM + NSP loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da65dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | loss = 54.528709\n",
      "Epoch 2/10 | loss = 28.608776\n",
      "Epoch 3/10 | loss = 25.306143\n",
      "Epoch 4/10 | loss = 24.880194\n",
      "Epoch 5/10 | loss = 25.955692\n",
      "Epoch 6/10 | loss = 22.312098\n",
      "Epoch 7/10 | loss = 14.980156\n",
      "Epoch 8/10 | loss = 30.211126\n",
      "Epoch 9/10 | loss = 23.572529\n",
      "Epoch 10/10 | loss = 21.204180\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model = BERT().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch = make_batch()\n",
    "    input_ids, segment_ids, masked_tokens, masked_pos, is_next = map(torch.LongTensor, zip(*batch))\n",
    "    input_ids = input_ids.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    masked_tokens = masked_tokens.to(device)\n",
    "    masked_pos = masked_pos.to(device)\n",
    "    is_next = is_next.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
    "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens).mean()\n",
    "    loss_nsp = criterion(logits_nsp, is_next)\n",
    "    loss = loss_lm + loss_nsp\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | loss = {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454da67c",
   "metadata": {},
   "source": [
    "### Model Serialization\n",
    "\n",
    "Saving trained BERT weights and tokenizer configuration for downstream fine-tuning. The serialized artifacts include:\n",
    "- Model state dictionary with trained parameters\n",
    "- Tokenizer metadata (vocabulary, hyperparameters)\n",
    "- Architecture configuration for reproducible loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d359f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/bert_state_dict.pt\")\n",
    "\n",
    "tokenizer_metadata = {\n",
    "    \"word2id\": word2id,\n",
    "    \"id2word\": id2word,\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"max_len\": max_len,\n",
    "    \"max_mask\": max_mask,\n",
    "    \"d_model\": d_model,\n",
    "    \"n_layers\": n_layers,\n",
    "    \"n_heads\": n_heads,\n",
    "    \"d_ff\": d_ff,\n",
    "    \"d_k\": d_k,\n",
    "    \"d_v\": d_v,\n",
    "    \"n_segments\": n_segments\n",
    "}\n",
    "with open(\"models/tokenizer_metadata.json\", \"w\") as f:\n",
    "    json.dump(tokenizer_metadata, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f4733",
   "metadata": {},
   "source": [
    "## Sentence-BERT for Natural Language Inference\n",
    "\n",
    "![Sentence-BERT Architecture](figures/sbert-architecture.png)\n",
    "\n",
    "**Dataset:** Stanford Natural Language Inference (SNLI) from Hugging Face\n",
    "\n",
    "**Architecture:** Siamese network structure with shared BERT encoder for processing premise-hypothesis pairs\n",
    "\n",
    "**Label mapping:** 0=entailment, 1=neutral, 2=contradiction\n",
    "\n",
    "### Approach\n",
    "Extending pre-trained BERT with Siamese architecture to generate semantically meaningful sentence embeddings. Using mean pooling over token representations and SoftmaxLoss classification objective as described in the Sentence-BERT paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ad4b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['premise', 'hypothesis', 'label'],\n",
       "     num_rows: 50000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['premise', 'hypothesis', 'label'],\n",
       "     num_rows: 5000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['premise', 'hypothesis', 'label'],\n",
       "     num_rows: 5000\n",
       " }))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snli = load_dataset(\"snli\")\n",
    "snli = snli.filter(lambda x: x[\"label\"] != -1)\n",
    "\n",
    "train_size = 50000\n",
    "val_size = 5000\n",
    "test_size = 5000\n",
    "\n",
    "snli_train = snli[\"train\"].shuffle(seed=seed).select(list(range(train_size)))\n",
    "snli_val = snli[\"validation\"].shuffle(seed=seed).select(list(range(val_size)))\n",
    "snli_test = snli[\"test\"].shuffle(seed=seed).select(list(range(test_size)))\n",
    "snli_train, snli_val, snli_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ece4caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"[.,!?\\-]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def encode_sentence(text, max_len, word2id):\n",
    "    tokens = [word2id.get(w, word2id[\"[UNK]\"]) for w in clean_text(text).split()]\n",
    "    tokens = tokens[: max_len - 2]\n",
    "    input_ids = [word2id[\"[CLS]\"]] + tokens + [word2id[\"[SEP]\"]]\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    pad_len = max_len - len(input_ids)\n",
    "    input_ids.extend([word2id[\"[PAD]\"]] * pad_len)\n",
    "    attention_mask.extend([0] * pad_len)\n",
    "\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f065335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SNLIDataset(Dataset):\n",
    "    def __init__(self, dataset, word2id, max_len):\n",
    "        self.dataset = dataset\n",
    "        self.word2id = word2id\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        premise_ids, premise_mask = encode_sentence(item[\"premise\"], self.max_len, self.word2id)\n",
    "        hypothesis_ids, hypothesis_mask = encode_sentence(item[\"hypothesis\"], self.max_len, self.word2id)\n",
    "        label = item[\"label\"]\n",
    "        return {\n",
    "            \"premise_input_ids\": torch.tensor(premise_ids, dtype=torch.long),\n",
    "            \"premise_attention_mask\": torch.tensor(premise_mask, dtype=torch.long),\n",
    "            \"hypothesis_input_ids\": torch.tensor(hypothesis_ids, dtype=torch.long),\n",
    "            \"hypothesis_attention_mask\": torch.tensor(hypothesis_mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "train_dataset = SNLIDataset(snli_train, word2id, max_len)\n",
    "val_dataset = SNLIDataset(snli_val, word2id, max_len)\n",
    "test_dataset = SNLIDataset(snli_test, word2id, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "next(iter(train_loader)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b37795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (embedding): Embedding(\n",
       "    (tok_embed): Embedding(307179, 128)\n",
       "    (pos_embed): Embedding(64, 128)\n",
       "    (seg_embed): Embedding(2, 128)\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x EncoderLayer(\n",
       "      (enc_self_attn): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ffn): PoswiseFeedForwardNet(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (activ): Tanh()\n",
       "  (linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (decoder): Linear(in_features=128, out_features=307179, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload metadata and BERT weights\n",
    "with open(\"models/tokenizer_metadata.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# Ensure config matches Task 1\n",
    "vocab_size = meta[\"vocab_size\"]\n",
    "max_len = meta[\"max_len\"]\n",
    "d_model = meta[\"d_model\"]\n",
    "n_layers = meta[\"n_layers\"]\n",
    "n_heads = meta[\"n_heads\"]\n",
    "d_ff = meta[\"d_ff\"]\n",
    "d_k = meta[\"d_k\"]\n",
    "d_v = meta[\"d_v\"]\n",
    "n_segments = meta[\"n_segments\"]\n",
    "\n",
    "model = BERT().to(device)\n",
    "model.load_state_dict(torch.load(\"models/bert_state_dict.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6eacb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool(token_embeds, attention_mask):\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "    pool = torch.sum(token_embeds * in_mask, dim=1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
    "    return pool\n",
    "\n",
    "classifier_head = nn.Linear(d_model * 3, 3).to(device)\n",
    "\n",
    "optimizer_bert = optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_head = optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16db79c",
   "metadata": {},
   "source": [
    "### SoftmaxLoss Classification Objective\n",
    "\n",
    "![Sentence-BERT Ablation Results](figures/sbert-ablation.png)\n",
    "\n",
    "**Mathematical formulation:** \n",
    "\n",
    "For sentence embeddings $u$ (premise) and $v$ (hypothesis), we compute:\n",
    "\n",
    "$$\\text{softmax}(W^T \\cdot [u, v, |u - v|])$$\n",
    "\n",
    "**Feature engineering:** Concatenating sentence representations with element-wise absolute difference provides:\n",
    "- $u$: Premise semantic representation\n",
    "- $v$: Hypothesis semantic representation  \n",
    "- $|u - v|$: Direct similarity/difference signal\n",
    "\n",
    "This approach enables effective learning of entailment, contradiction, and neutral relationships between sentence pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae9fb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | loss = 1.197853\n",
      "Epoch 2/10 | loss = 1.169433\n",
      "Epoch 3/10 | loss = 0.874216\n",
      "Epoch 4/10 | loss = 0.844671\n",
      "Epoch 5/10 | loss = 1.243289\n",
      "Epoch 6/10 | loss = 0.873917\n",
      "Epoch 7/10 | loss = 1.116049\n",
      "Epoch 8/10 | loss = 0.932725\n",
      "Epoch 9/10 | loss = 0.867806\n",
      "Epoch 10/10 | loss = 0.776927\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.train()\n",
    "classifier_head.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        optimizer_bert.zero_grad()\n",
    "        optimizer_head.zero_grad()\n",
    "\n",
    "        inputs_a = batch[\"premise_input_ids\"].to(device)\n",
    "        inputs_b = batch[\"hypothesis_input_ids\"].to(device)\n",
    "        attention_a = batch[\"premise_attention_mask\"].to(device)\n",
    "        attention_b = batch[\"hypothesis_attention_mask\"].to(device)\n",
    "        label = batch[\"labels\"].to(device)\n",
    "\n",
    "        segment_ids_a = torch.zeros_like(inputs_a).to(device)\n",
    "        segment_ids_b = torch.zeros_like(inputs_b).to(device)\n",
    "\n",
    "        u = model.encode(inputs_a, segment_ids_a)\n",
    "        v = model.encode(inputs_b, segment_ids_b)\n",
    "\n",
    "        u_mean = mean_pool(u, attention_a)\n",
    "        v_mean = mean_pool(v, attention_b)\n",
    "\n",
    "        uv_abs = torch.abs(u_mean - v_mean)\n",
    "        x = torch.cat([u_mean, v_mean, uv_abs], dim=-1)\n",
    "        logits = classifier_head(x)\n",
    "\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer_bert.step()\n",
    "        optimizer_head.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | loss = {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9d30c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"bert_state_dict\": model.state_dict(),\n",
    "    \"classifier_state_dict\": classifier_head.state_dict(),\n",
    "}, \"models/sbert_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2dd16",
   "metadata": {},
   "source": [
    "## Model Evaluation and Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "521b2565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.61      0.63      0.62      1716\n",
      "      neutral       0.60      0.49      0.54      1622\n",
      "contradiction       0.53      0.62      0.57      1662\n",
      "\n",
      "     accuracy                           0.58      5000\n",
      "    macro avg       0.58      0.58      0.58      5000\n",
      " weighted avg       0.58      0.58      0.58      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "classifier_head.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs_a = batch[\"premise_input_ids\"].to(device)\n",
    "        inputs_b = batch[\"hypothesis_input_ids\"].to(device)\n",
    "        attention_a = batch[\"premise_attention_mask\"].to(device)\n",
    "        attention_b = batch[\"hypothesis_attention_mask\"].to(device)\n",
    "        label = batch[\"labels\"].to(device)\n",
    "\n",
    "        segment_ids_a = torch.zeros_like(inputs_a).to(device)\n",
    "        segment_ids_b = torch.zeros_like(inputs_b).to(device)\n",
    "\n",
    "        u = model.encode(inputs_a, segment_ids_a)\n",
    "        v = model.encode(inputs_b, segment_ids_b)\n",
    "\n",
    "        u_mean = mean_pool(u, attention_a)\n",
    "        v_mean = mean_pool(v, attention_b)\n",
    "\n",
    "        uv_abs = torch.abs(u_mean - v_mean)\n",
    "        x = torch.cat([u_mean, v_mean, uv_abs], dim=-1)\n",
    "        logits = classifier_head(x)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.extend(preds.cpu().numpy().tolist())\n",
    "        all_labels.extend(label.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"entailment\", \"neutral\", \"contradiction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f98a82ab-b4ce-41c7-a313-a8de7c28b189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Compute the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 2. Setup the display with your specific class names\n",
    "target_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "\n",
    "# 3. Plot the matrix\n",
    "# cmap=plt.cm.Blues makes it blue; remove it for default colors\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f9f85-6a2e-486f-9959-f592bcaff660",
   "metadata": {},
   "source": [
    "## Model Inference and Similarity Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37815112-ecae-4486-89bd-1d034feb4b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.3526\n"
     ]
    }
   ],
   "source": [
    "# Load the trained S-BERT model and classifier head\n",
    "sbert_checkpoint = torch.load(\"models/sbert_state_dict.pt\", map_location=device)\n",
    "\n",
    "# Reload metadata and BERT weights\n",
    "with open(\"models/tokenizer_metadata.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# Ensure config matches Task 1\n",
    "vocab_size = meta[\"vocab_size\"]\n",
    "max_len = meta[\"max_len\"]\n",
    "d_model = meta[\"d_model\"]\n",
    "n_layers = meta[\"n_layers\"]\n",
    "n_heads = meta[\"n_heads\"]\n",
    "d_ff = meta[\"d_ff\"]\n",
    "d_k = meta[\"d_k\"]\n",
    "d_v = meta[\"d_v\"]\n",
    "n_segments = meta[\"n_segments\"]\n",
    "word2id = meta[\"word2id\"]\n",
    "\n",
    "# Initialize and load model state\n",
    "model = BERT().to(device)\n",
    "model.load_state_dict(sbert_checkpoint[\"bert_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "classifier_head = nn.Linear(d_model * 3, 3).to(device)\n",
    "classifier_head.load_state_dict(sbert_checkpoint[\"classifier_state_dict\"])\n",
    "classifier_head.eval()\n",
    "\n",
    "def calculate_similarity(model, word2id, sentence_a, sentence_b, device, max_len):\n",
    "    # Encode sentences using the custom function\n",
    "    ids_a, mask_a = encode_sentence(sentence_a, max_len, word2id)\n",
    "    ids_b, mask_b = encode_sentence(sentence_b, max_len, word2id)\n",
    "\n",
    "    # Convert to tensors and add batch dimension\n",
    "    inputs_ids_a = torch.tensor(ids_a, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    attention_a = torch.tensor(mask_a, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    inputs_ids_b = torch.tensor(ids_b, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    attention_b = torch.tensor(mask_b, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Create dummy segment IDs (as the model expects them)\n",
    "    segment_ids_a = torch.zeros_like(inputs_ids_a).to(device)\n",
    "    segment_ids_b = torch.zeros_like(inputs_ids_b).to(device)\n",
    "\n",
    "    # Extract token embeddings from BERT encoder\n",
    "    with torch.no_grad():\n",
    "        u_embed = model.encode(inputs_ids_a, segment_ids_a)\n",
    "        v_embed = model.encode(inputs_ids_b, segment_ids_b)\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u = mean_pool(u_embed, attention_a).detach().cpu().numpy()\n",
    "    v = mean_pool(v_embed, attention_b).detach().cpu().numpy()\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(u, v)[0, 0]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Example usage:\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, word2id, sentence_a, sentence_b, device, max_len)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00fc58",
   "metadata": {},
   "source": [
    "### Performance Analysis & Limitations\n",
    "\n",
    "**Current Achievements:**\n",
    "- Successfully trained BERT from scratch with MLM + NSP objectives\n",
    "- Implemented effective Siamese architecture for sentence similarity\n",
    "- Achieved 58% accuracy on SNLI test set with balanced class performance\n",
    "- Developed functional web application with real-time inference\n",
    "\n",
    "**Identified Limitations:**\n",
    "- **Computational Constraints**: Reduced model size (2 layers vs. 12 in BERT-base) limits representational capacity\n",
    "- **Limited Dataset Coverage**: Subset training (5M samples vs. full BookCorpus) reduces vocabulary and context diversity\n",
    "- **Simplified Architecture**: Basic tokenization strategy compared to WordPiece/BPE used in production models\n",
    "- **Training Duration**: Limited epochs may not achieve full convergence\n",
    "\n",
    "**Proposed Enhancements:**\n",
    "1. **Architectural Scaling**: Expand to BERT-base dimensions (12 layers, 768 hidden units, 12 attention heads)\n",
    "2. **Advanced Tokenization**: Implement WordPiece or Byte-Pair Encoding for better subword representation\n",
    "3. **Extended Corpus Training**: Utilize complete BookCorpus and additional corpora for comprehensive pre-training\n",
    "4. **Enhanced Fine-tuning**: Implement hard negative mining and curriculum learning for improved NLI performance\n",
    "5. **Ensemble Methods**: Combine multiple model predictions for robust inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf84c8f6",
   "metadata": {},
   "source": [
    "## Web Application Architecture\n",
    "\n",
    "### Implementation Overview\n",
    "Developed a production-ready Flask web application providing real-time Natural Language Inference predictions using our custom-trained Sentence-BERT model.\n",
    "\n",
    "### Key Features\n",
    "- **Interactive Interface**: Dual text input fields for premise and hypothesis\n",
    "- **Real-time Processing**: Immediate NLI classification with visual feedback\n",
    "- **Model Integration**: Direct deployment of trained Sentence-BERT pipeline\n",
    "- **User Experience**: Color-coded results (green=entailment, yellow=neutral, red=contradiction)\n",
    "\n",
    "### Example Usage\n",
    "**Input:**\n",
    "- *Premise*: \"A man is playing a guitar on stage\"\n",
    "- *Hypothesis*: \"The man is singing\"\n",
    "\n",
    "**Output:** *Entailment* (High semantic agreement)\n",
    "\n",
    "### Technical Implementation\n",
    "The web application (`app/app.py`) loads serialized model weights, implements the complete inference pipeline (tokenization → encoding → similarity computation → classification), and serves predictions via RESTful API endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e2a48",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "> **Assignment Definition**\n",
    "> Chaklam Silpasuwanchai, Todsavad Tangtortan\n",
    "> Updated 19 January 2026\n",
    "> AT82.05 Artificial Intelligence: Natural Language Understanding (NLU)\n",
    "> **A4: Do you AGREE?**\n",
    "\n",
    "- Devlin, J., Chang, M. W., Lee, K., and Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\n",
    "- Reimers, N., and Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.\n",
    "- BookCorpus dataset (Hugging Face).\n",
    "- SNLI dataset (Hugging Face)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
